{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for texts\n",
      "newsafr.json : ['туристов', 'компании', 'wilderness', 'странах', 'туризма', 'туристы', 'африканских', 'которые', 'носорогов', 'является']\n",
      "newscy.json : ['туристов', 'seasons', 'россиян', 'человек', 'интерфакс', 'которые', 'турпотока', 'сообщает', 'сравнению', 'стоимость']\n",
      "newsfr.json : ['туристов', 'seasons', 'россиян', 'человек', 'интерфакс', 'которые', 'турпотока', 'сообщает', 'сравнению', 'стоимость']\n",
      "newsit.json : ['землетрясения', 'человек', 'интерфакс', 'центральной', 'которые', 'октября', 'землетрясение', 'туристов', 'несколько', 'который']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import chardet\n",
    "\n",
    "def detect_enconding(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = f.read()\n",
    "        encoding_result = chardet.detect(data)['encoding']\n",
    "        return encoding_result\n",
    "\n",
    "def file_to_json(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = f.read()\n",
    "    data_json = json.loads(data.decode(detect_enconding(filename)))\n",
    "    return data_json\n",
    "\n",
    "def merge_texts_split_by_words(input_json):\n",
    "    result = []\n",
    "    for text in input_json['rss']['channel']['items']:\n",
    "        result += text['description'].lower().split(' ')\n",
    "    return result\n",
    "\n",
    "def top_n_words_count(input_list, n):\n",
    "    word_counter = {}\n",
    "    for word in set(input_list):\n",
    "        if len(word) > 6:\n",
    "            word_counter[word] = input_list.count(word)\n",
    "    result = sorted(word_counter, key=word_counter.get, reverse=True)[:n]\n",
    "    return result\n",
    "\n",
    "def print_result(filename, n):\n",
    "    data_json = file_to_json(filename)\n",
    "    data_list = merge_texts_split_by_words(data_json)\n",
    "    top_n_words = top_n_words_count(data_list, n)\n",
    "    print(filename, ':', top_n_words)\n",
    "\n",
    "filename_list = ['newsafr.json', 'newscy.json', 'newsfr.json', 'newsit.json']\n",
    "n = 10\n",
    "\n",
    "print('Top ' + str(n) + ' words for texts')\n",
    "for filename in filename_list:\n",
    "    print_result(filename, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
